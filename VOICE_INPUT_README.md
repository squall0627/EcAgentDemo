# 音声入力機能 (Voice Input Feature)

このドキュメントでは、EcAgentDemoに新しく追加された音声入力機能について説明します。

## 概要

音声入力機能により、ユーザーはマイクを使用して音声でチャットシステムに入力できるようになりました。音声はOpenAI Whisper APIを使用してテキストに変換され、既存のチャットワークフローに統合されます。

## 機能

- 🎤 **音声録音**: ブラウザのMediaRecorder APIを使用したリアルタイム音声録音
- 🔄 **音声変換**: OpenAI Whisper APIによる高精度な音声からテキストへの変換
- 🌐 **多言語対応**: 日本語を中心とした音声認識（設定で変更可能）
- 🎨 **視覚的フィードバック**: 録音状態、処理状態を示すボタンの色変化とアニメーション
- ⚡ **シームレス統合**: 既存のチャットワークフローとの完全統合

## セットアップ

### 1. 必要な依存関係

音声入力機能は既存の依存関係を使用します：
- `openai` - OpenAI Whisper API用
- `fastapi` - API エンドポイント用
- `python-multipart` - ファイルアップロード用

### 2. 環境変数の設定

`.env` ファイルに以下を追加してください：

```env
OPENAI_API_KEY=your_openai_api_key_here
```

### 3. サポートされている音声フォーマット

以下の音声フォーマットがサポートされています：
- WAV
- MP3
- MP4
- MPEG
- MPGA
- M4A
- WEBM
- FLAC
- OGG

## 使用方法

### フロントエンド

1. **音声録音の開始**:
   - チャット入力欄の横にある🎤ボタンをクリック
   - ブラウザがマイクへのアクセス許可を求めた場合は「許可」をクリック
   - ボタンが赤色に変わり、⏹️アイコンが表示されます

2. **音声録音の停止**:
   - 録音中に🎤ボタン（⏹️アイコン）を再度クリック
   - ボタンが黄色に変わり、⏳アイコンが表示されて処理中であることを示します

3. **結果の確認**:
   - 音声がテキストに変換され、入力欄に自動的に入力されます
   - エージェントの応答も自動的に生成・表示されます

### API エンドポイント

#### POST `/api/chat/voice_input`

音声ファイルを受け取り、テキストに変換してチャット処理を行います。

**パラメータ**:
- `audio_file` (ファイル): 音声ファイル
- `session_id` (文字列, オプション): セッションID
- `user_id` (文字列, オプション): ユーザーID
- `agent_type` (文字列, オプション): エージェントタイプ（デフォルト: "default"）
- `llm_type` (文字列, オプション): LLMタイプ（デフォルト: "ollama"）
- `context` (文字列, オプション): コンテキスト情報

**レスポンス**:
```json
{
  "status": "success",
  "transcribed_text": "変換されたテキスト",
  "agent_response": {...},
  "message": "音声入力が正常に処理されました"
}
```

## 技術詳細

### アーキテクチャ

```
フロントエンド (HTML/JS)
    ↓ 音声録音 (MediaRecorder API)
    ↓ FormData でアップロード
API エンドポイント (/api/chat/voice_input)
    ↓ 音声ファイル処理
VoiceService (services/voice_service.py)
    ↓ OpenAI Whisper API 呼び出し
    ↓ テキスト変換
既存のチャットワークフロー
    ↓ エージェント処理
レスポンス表示
```

### 主要コンポーネント

#### 1. VoiceService (`services/voice_service.py`)
- OpenAI Whisper APIとの統合
- 音声ファイルの一時保存と処理
- エラーハンドリング

#### 2. API エンドポイント (`api/routers/chat_api.py`)
- ファイルアップロード処理
- 音声からテキストへの変換
- 既存チャットワークフローとの統合

#### 3. フロントエンド統合
- **HTML**: 音声入力ボタンの追加
- **CSS**: ボタンスタイルと状態表示
- **JavaScript**: 音声録音とAPI通信

### セキュリティ考慮事項

- 音声ファイルは一時的にサーバーに保存され、処理後すぐに削除されます
- OpenAI APIキーは環境変数で安全に管理されます
- ファイルサイズとフォーマットの検証が行われます

## トラブルシューティング

### よくある問題

1. **「マイクへのアクセスが拒否されました」**
   - ブラウザの設定でマイクアクセスを許可してください
   - HTTPSでアクセスしていることを確認してください（一部ブラウザで必要）

2. **「音声機能が利用できません」**
   - OPENAI_API_KEYが正しく設定されているか確認してください
   - OpenAIアカウントに十分なクレジットがあるか確認してください

3. **「音声からテキストを抽出できませんでした」**
   - 音声が明確に録音されているか確認してください
   - 背景ノイズが少ない環境で録音してください
   - サポートされている音声フォーマットを使用してください

### デバッグ

開発者ツールのコンソールで以下を確認できます：
- 音声録音の開始/停止ログ
- API呼び出しの詳細
- エラーメッセージ

## テスト

音声入力機能をテストするには：

```bash
python test_voice_functionality.py
```

このスクリプトは以下をチェックします：
- 環境設定（API キーなど）
- API構造の整合性
- フロントエンド統合
- 音声サービスの動作（API キーが設定されている場合）

## 今後の改善予定

- [ ] 音声録音の最大時間制限
- [ ] 複数言語の音声認識サポート
- [ ] 音声品質の自動調整
- [ ] オフライン音声認識オプション
- [ ] 音声コマンドのカスタマイズ

## サポート

問題が発生した場合は、以下を確認してください：
1. 環境変数の設定
2. 依存関係のインストール
3. ブラウザの互換性
4. ネットワーク接続

---

**注意**: この機能はOpenAI Whisper APIを使用するため、インターネット接続とOpenAI APIキーが必要です。