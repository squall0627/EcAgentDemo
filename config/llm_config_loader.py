import json
import os
from typing import Dict, List, Optional, Any
from pathlib import Path

class LLMConfigLoader:
    """LLMшинхоЪуГнуГ╝уГАуГ╝"""
    
    def __init__(self, config_path: str = Path(__file__).parent / "llm_config.json"):
        self.config_path = Path(config_path)
        self._config_cache = None
        self._load_config()
    
    def _load_config(self) -> None:
        """шинхоЪуГХуВбуВдуГлуВТшкнуБ┐ш╛╝уВА"""
        try:
            if self.config_path.exists():
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    self._config_cache = json.load(f)
            else:
                # уГЗуГХуВйуГлуГИшинхоЪуВТф╜ЬцИР
                self._create_default_config()
                print(f"тЪая╕П шинхоЪуГХуВбуВдуГлуБМхнШхЬиуБЧуБ╛уБЫуВУуАВуГЗуГХуВйуГлуГИшинхоЪуВТф╜ЬцИРуБЧуБ╛уБЧуБЯ: {self.config_path}")
        except Exception as e:
            print(f"тЭМ шинхоЪуГХуВбуВдуГлуБошкнуБ┐ш╛╝уБ┐уБлхд▒цХЧуБЧуБ╛уБЧуБЯ: {e}")
            self._config_cache = self._get_fallback_config()
    
    def _create_default_config(self) -> None:
        """уГЗуГХуВйуГлуГИшинхоЪуГХуВбуВдуГлуВТф╜ЬцИР"""
        # configуГЗуВгуГмуВпуГИуГкуВТф╜ЬцИРя╝ИхнШхЬиуБЧуБкуБДха┤хРИя╝Й
        self.config_path.parent.mkdir(parents=True, exist_ok=True)
        
        default_config = self._get_fallback_config()
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(default_config, f, ensure_ascii=False, indent=2)
        self._config_cache = default_config
    
    def _get_fallback_config(self) -> Dict[str, Any]:
        """уГХуВйуГ╝уГлуГРуГГуВпшинхоЪуВТхПЦх╛Ч"""
        return {
            "llm_models": [
                {
                    "value": "ollama_qwen3",
                    "label": "ЁЯжЩ Ollama - Qwen3 30B",
                    "provider": "ollama",
                    "model": "qwen3:30b",
                    "base_url": "http://localhost:11434",
                    "temperature": 0.7,
                    "color": "ollama",
                    "description": "уГЗуГХуВйуГлуГИуГнуГ╝уВлуГлуГвуГЗуГл",
                    "default": True
                }
            ],
            "provider_settings": {
                "ollama": {
                    "requires_api_key": False,
                    "default_base_url": "http://localhost:11434",
                    "fallback_model": "qwen3:30b"
                }
            }
        }
    
    def get_all_models(self) -> List[Dict[str, Any]]:
        """уБЩуБ╣уБжуБоLLMуГвуГЗуГлшинхоЪуВТхПЦх╛Ч"""
        return self._config_cache.get("llm_models", [])
    
    def get_model_config(self, model_value: str) -> Optional[Dict[str, Any]]:
        """чЙ╣хоЪуБоуГвуГЗуГлшинхоЪуВТхПЦх╛Ч"""
        models = self.get_all_models()
        for model in models:
            if model.get("value") == model_value:
                return model
        return None
    
    def get_default_model(self) -> str:
        """уГЗуГХуВйуГлуГИуГвуГЗуГлуБохАдуВТхПЦх╛Ч"""
        models = self.get_all_models()
        for model in models:
            if model.get("default", False):
                return model.get("value")
        # уГЗуГХуВйуГлуГИуБМшинхоЪуБХуВМуБжуБДуБкуБДха┤хРИуАБцЬАхИЭуБоуГвуГЗуГлуВТш┐ФуБЩ
        return models[0].get("value") if models else "ollama_qwen"
    
    def get_provider_settings(self, provider: str) -> Dict[str, Any]:
        """уГЧуГнуГРуВдуГАуГ╝шинхоЪуВТхПЦх╛Ч"""
        provider_settings = self._config_cache.get("provider_settings", {})
        return provider_settings.get(provider, {})
    
    def get_models_by_provider(self, provider: str) -> List[Dict[str, Any]]:
        """уГЧуГнуГРуВдуГАуГ╝хИеуБоуГвуГЗуГлуГкуВ╣уГИуВТхПЦх╛Ч"""
        models = self.get_all_models()
        return [model for model in models if model.get("provider") == provider]
    
    def validate_model_availability(self, model_value: str) -> tuple[bool, str]:
        """уГвуГЗуГлуБохИйчФихПпшГ╜цАзуВТцдЬши╝"""
        model_config = self.get_model_config(model_value)
        if not model_config:
            return False, f"уГвуГЗуГл '{model_value}' уБпшинхоЪуБХуВМуБжуБДуБ╛уБЫуВУ"
        
        provider = model_config.get("provider")
        provider_settings = self.get_provider_settings(provider)
        
        # APIуВнуГ╝уБМх┐ЕшжБуБкха┤хРИуБоцдЬши╝
        if provider_settings.get("requires_api_key", False):
            api_key_env = provider_settings.get("api_key_env")
            if api_key_env and not os.getenv(api_key_env):
                return False, f"{provider} APIуВнуГ╝уБМшинхоЪуБХуВМуБжуБДуБ╛уБЫуВУ ({api_key_env})"
        
        return True, "хИйчФихПпшГ╜"
    
    def get_frontend_config(self) -> str:
        """уГХуГнуГ│уГИуВиуГ│уГЙчФиуБоJavaScriptшинхоЪуВТчФЯцИР"""
        models = self.get_all_models()
        return json.dumps(models, ensure_ascii=False)
    
    def reload_config(self) -> None:
        """шинхоЪуВТхЖНшкнуБ┐ш╛╝уБ┐"""
        self._config_cache = None
        self._load_config()
        print("тЬЕ LLMшинхоЪуБМхЖНшкнуБ┐ш╛╝уБ┐уБХуВМуБ╛уБЧуБЯ")

# уВ░уГнуГ╝уГРуГлуВдуГ│уВ╣уВ┐уГ│уВ╣
llm_config = LLMConfigLoader()